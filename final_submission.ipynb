{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from typing import Tuple, Union, Optional, List, Dict, Set\n",
    "from implicit.nearest_neighbours import CosineRecommender, TFIDFRecommender\n",
    "from numpy.core.multiarray import ndarray\n",
    "from scipy.sparse import coo_matrix\n",
    "from ml_metrics import mapk\n",
    "from tqdm import tqdm\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(data: pd.DataFrame) -> Dict[int, List[int]]:\n",
    "    target = dict()\n",
    "    for row in data.itertuples():\n",
    "        target[int(row.user_id)] = [int(row.course_id)]\n",
    "    return target\n",
    "\n",
    "def train_val_split(dataset: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[int, List[int]]]:\n",
    "    X = dataset.copy()\n",
    "    X.reset_index(inplace=True)\n",
    "    X.sort_values([\"user_id\", \"index\"], inplace=True)\n",
    "    \n",
    "    X[\"order\"] = 1\n",
    "    X[\"order\"] = X.groupby(\"user_id\")[\"order\"].cumsum()\n",
    "    \n",
    "    max_order = X.groupby(\"user_id\", as_index=False)[\"order\"].max()\n",
    "    max_order[\"is_max_order\"] = 1\n",
    "    \n",
    "    X = X.merge(max_order, \"left\", on=[\"user_id\", \"order\"])\n",
    "    X[\"is_max_order\"] = X[\"is_max_order\"].fillna(0).astype(int)\n",
    "    \n",
    "    courses_in_train = X.loc[(X[\"is_max_order\"] == 0) | ((X[\"is_max_order\"] == 1) & (X[\"order\"] == 1)), \"course_id\"].unique()\n",
    "    \n",
    "    mask = (X[\"is_max_order\"] == 1) & (X[\"order\"] != 1) & (X[\"course_id\"].isin(courses_in_train))\n",
    "    \n",
    "    X_train = X.loc[~mask, ['user_id','course_id']].copy()\n",
    "    y_train = get_target(X.loc[mask, ['user_id','course_id']])\n",
    "    return X_train, y_train\n",
    "\n",
    "def transform_with_transformation_inplace(column, data, transformation):\n",
    "    _drop_non_transformed_rows(column, data, transformation)\n",
    "\n",
    "    non_null_values_mask = ~data[column].isnull().values\n",
    "    non_null_values = data.loc[non_null_values_mask, column].values.astype(int, copy=False)\n",
    "    transformed = transformation.values[np.searchsorted(transformation.index.values, non_null_values)]\n",
    "    del non_null_values\n",
    "    gc.collect()\n",
    "\n",
    "    data.loc[non_null_values_mask, column] = transformed\n",
    "    del non_null_values_mask\n",
    "    gc.collect()\n",
    "\n",
    "    data[column] = data[column].astype(int, errors=\"ignore\")\n",
    "\n",
    "\n",
    "def _drop_non_transformed_rows(column, data, transformation):\n",
    "    not_transformed = ~fast_isin_for_sorted_test_elements(data[column], transformation.index)\n",
    "    data.drop(index=data.index[~pd.isnull(data[column]) & not_transformed], inplace=True)\n",
    "\n",
    "\n",
    "def fast_isin_for_sorted_test_elements(elements: np.ndarray, sorted_test_elements: Union[np.ndarray, pd.Series]) -> np.ndarray:\n",
    "    if isinstance(sorted_test_elements, pd.Series):\n",
    "        sorted_test_elements = sorted_test_elements.values\n",
    "\n",
    "    if sorted_test_elements.size == 0:\n",
    "        return np.zeros(elements.size, dtype=np.bool)\n",
    "    if sorted_test_elements.size == 1:\n",
    "        return elements == sorted_test_elements[0]\n",
    "    ss_result_left = np.searchsorted(sorted_test_elements, elements, side=\"left\")\n",
    "    ss_result_left.clip(max=len(sorted_test_elements) - 1, out=ss_result_left)\n",
    "    result = elements == sorted_test_elements[ss_result_left]\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_id_transformations(data: pd.DataFrame, column: str) -> Tuple[pd.Series, pd.Series]:\n",
    "    \"\"\"E.g.\n",
    "        data = pd.DataFrame({'id': [10, None, 30], 'value': [0.1, 0.3, 0.2]})\n",
    "        column = 'id'\n",
    "\n",
    "        Returns:\n",
    "            pd.Series([10, 30, NONE_CONSTANT], index=[0, 1, 2], name='id')\n",
    "        pd.Series([0, 1, 2], index=[10, 30, NONE_CONSTANT], name='id')\n",
    "    \"\"\"\n",
    "    add_nan = False\n",
    "    values = data[column].unique()\n",
    "\n",
    "    if any(pd.isnull(values)):\n",
    "        values = values[~pd.isnull(values)]\n",
    "        add_nan = True\n",
    "\n",
    "    index = np.arange(len(values))\n",
    "    transformation = pd.Series(values, index=index, name=\"_\" + column)\n",
    "\n",
    "    if add_nan:\n",
    "        transformation = transformation.append(pd.Series([NONE_CONSTANT], index=[transformation.index.max() + 1]))\n",
    "\n",
    "    revert_transformation = pd.Series(transformation.index, index=transformation.values, name=\"_\" + column)\n",
    "    revert_transformation.sort_index(inplace=True)\n",
    "\n",
    "    return transformation, revert_transformation\n",
    "\n",
    "\n",
    "def get_course_user_matrix(\n",
    "    products: pd.Series, users: pd.Series, matrix_shape: Tuple[int, int], max_value: Optional[int] = None\n",
    ") -> coo_matrix:\n",
    "    if len(products) != len(users):\n",
    "        raise ValueError(\"Series with products and users must be the same length\")\n",
    "\n",
    "    data = np.ones(products.shape[0])\n",
    "    matrix = coo_matrix((data, (products, users)), shape=matrix_shape, dtype=np.float32)\n",
    "    if max_value is not None:\n",
    "        matrix = matrix.tocsr()\n",
    "        matrix.data = matrix.data.clip(max=max_value)\n",
    "        matrix = matrix.tocoo()\n",
    "    return matrix\n",
    "\n",
    "def get_recommendations(model: Union[CosineRecommender, TFIDFRecommender], product_user_matrix: coo_matrix, user_ids_to_predict: ndarray, user_id_to_compressed_user_id: pd.Series, compressed_product_id_to_product_id: pd.Series, n: int = 3) -> List[ndarray]:\n",
    "    recommendations = list()\n",
    "    user_product_matrix = product_user_matrix.T.tocsr()\n",
    "\n",
    "    for user_id, transformed_user_id in tqdm(zip(user_ids_to_predict, user_id_to_compressed_user_id[user_ids_to_predict].values)):\n",
    "        recommendation = model.recommend(userid=transformed_user_id, user_items=user_product_matrix, N=n, recalculate_user=False)\n",
    "        recommendation = [id for (id, score) in recommendation]\n",
    "        recommendation = compressed_product_id_to_product_id[np.array(recommendation)].values.tolist()\n",
    "        recommendations.append(recommendation)\n",
    "    return recommendations\n",
    "\n",
    "def add_missing_recommendations(reco: List[int], reco_2: List[int]) -> List[int]:\n",
    "    for i in reco_2:\n",
    "        if len(reco) == 3:\n",
    "            break\n",
    "        if i in reco:\n",
    "            continue\n",
    "        reco += [i]\n",
    "    return reco\n",
    "\n",
    "def get_submission(test: pd.DataFrame) -> pd.DataFrame:\n",
    "    submission = pd.DataFrame({\"Id\": test[\"user_id\"].values})\n",
    "    recommendations_as_str = list()\n",
    "\n",
    "    for row in test.itertuples():\n",
    "        if row.Predicted is np.nan:\n",
    "            recommendations_as_str.append(\"7 1 15\")\n",
    "        else:\n",
    "            recommendations_as_str.append(\" \".join([str(i) for i in row.Predicted]))\n",
    "    submission[\"Predicted\"] = recommendations_as_str\n",
    "    return submission\n",
    "\n",
    "def convert_to_datetime(creation_datetime: str) -> datetime:\n",
    "    if \"\\ufeff\" in creation_datetime:\n",
    "        creation_datetime = creation_datetime.replace(\"\\ufeff\", \"\")\n",
    "    return datetime.strptime(creation_datetime, '%d-%m-%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RECO = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_train = pd.read_csv(\"assessment_train.csv\", index_col=0)\n",
    "course = pd.read_csv(\"course.csv\", delimiter=\";\") \n",
    "lessons_homework_train = pd.read_csv(\"lessons_homework_train.csv\", index_col=0)\n",
    "user_course_train = pd.read_csv(\"user_course_train.csv\", index_col=0)\n",
    "test = pd.read_csv(\"test_ids.txt\", header=None, names=[\"user_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"id\",\n",
    "    \"salary\",\n",
    "    \"enabled\",\n",
    "    \"shortname\",\n",
    "    \"visible\",\n",
    "    \"assessment_enabled\",\n",
    "    \"status\",\n",
    "    \"is_partner\",\n",
    "    \"is_success_experiment\",\n",
    "    \"created_date\",\n",
    "    \"is_specialization\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_features = course[columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-566dbf5a84eb>:6: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  course_features[\"created_date\"] = (pd.datetime(2021, 5, 15) - course_features[\"created_date\"]).dt.days\n"
     ]
    }
   ],
   "source": [
    "course_features[[\"salary\", \"enabled\"]] = course_features[[\"salary\", \"enabled\"]].fillna(-1).astype(int)\n",
    "course_features[\"shortname\"] = course_features[\"shortname\"].fillna(\"Unknown\")\n",
    "course_features[\"created_date\"] = course_features[\"created_date\"].fillna(\"2022-01-01\")\n",
    "\n",
    "course_features[\"created_date\"] = pd.to_datetime(course_features[\"created_date\"])\n",
    "course_features[\"created_date\"] = (pd.datetime(2021, 5, 15) - course_features[\"created_date\"]).dt.days\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "course_features[\"shortname\"] = le.fit_transform(course_features[\"shortname\"].values)\n",
    "course_features[\"status\"] = le.fit_transform(course_features[\"status\"].values)\n",
    "course_features.rename(columns={\"id\": \"course_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = user_course_train[[\"user_id\", \"created\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-b4a479124587>:3: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  user_features[\"created\"] = (pd.datetime(2021, 5, 15) - user_features[\"created\"]).dt.days\n"
     ]
    }
   ],
   "source": [
    "user_features[\"created\"] = user_features[\"created\"].str.replace(\".\", \"-\")\n",
    "user_features[\"created\"] = user_features[\"created\"].apply(convert_to_datetime)\n",
    "user_features[\"created\"] = (pd.datetime(2021, 5, 15) - user_features[\"created\"]).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = user_features.groupby([\"user_id\"], as_index=False).agg({\"created\": [\"min\", \"max\"]})\n",
    "user_features.columns = [\"user_id\", \"first_date\", \"last_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = user_course_train[['user_id','course_id']].copy().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_ids = assessment_train[\"user_id\"].unique()\n",
    "user_course_train_ids = user_course_train[\"user_id\"].unique()\n",
    "test_ids = test[\"user_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_ids = np.intersect1d(assessment_ids, test_ids)\n",
    "group_1 = np.intersect1d(user_course_train_ids, test_ids)\n",
    "group_2 = assessment_ids[~np.isin(assessment_ids, group_1)]\n",
    "group_3 = test_ids[~np.isin(test_ids, np.union1d(group_1, group_2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендации для пользователей, по которым есть информация по оплате и оценкам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e83dfbf13643f79f5c873e992f45d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=173.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58056e4f3bf140c1bfbe8786cd9b2a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=173.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "148it [00:00, 1423.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3017it [00:01, 2543.31it/s]\n",
      "3017it [00:01, 2469.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "X_train, y_val = train_val_split(X)\n",
    "\n",
    "n_users = X_train[\"user_id\"].nunique()\n",
    "n_courses = X_train[\"course_id\"].nunique()\n",
    "\n",
    "compressed_user_id_to_user_id, user_id_to_compressed_user_id = get_id_transformations(X_train, \"user_id\")\n",
    "compressed_course_id_to_course_id, course_id_to_compressed_course_id = get_id_transformations(X_train, \"course_id\")\n",
    "\n",
    "transform_with_transformation_inplace(\"user_id\", X_train, user_id_to_compressed_user_id)\n",
    "transform_with_transformation_inplace(\"course_id\", X_train, course_id_to_compressed_course_id)\n",
    "\n",
    "course_user_matrix_shape = (len(compressed_course_id_to_course_id), len(compressed_user_id_to_user_id))\n",
    "course_user_matrix = get_course_user_matrix(X_train[\"course_id\"], X_train[\"user_id\"], course_user_matrix_shape)\n",
    "\n",
    "model_1 = TFIDFRecommender(K=150)\n",
    "model_1.fit(course_user_matrix)\n",
    "\n",
    "model_2 = CosineRecommender(K=150)\n",
    "model_2.fit(course_user_matrix)\n",
    "\n",
    "actual = [course for course in y_val.values()]\n",
    "user_ids_to_predict = np.array([user_id for user_id in y_val.keys()])\n",
    "predicted_1_1 = get_recommendations(model_1, course_user_matrix, user_ids_to_predict, user_id_to_compressed_user_id, compressed_course_id_to_course_id, N_RECO)\n",
    "predicted_1_2 = get_recommendations(model_2, course_user_matrix, user_ids_to_predict, user_id_to_compressed_user_id, compressed_course_id_to_course_id, N_RECO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1851729090708209"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(actual, predicted_1_1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1858358192464921"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(actual, predicted_1_2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = list()\n",
    "\n",
    "for i, j in zip(predicted_1_1, predicted_1_2):\n",
    "    all_candidates = list(set(i) | set(j))\n",
    "    if len(all_candidates) < 3:\n",
    "        for wtf in [7, 1, 15]:\n",
    "            if wtf in all_candidates:\n",
    "                continue\n",
    "            if len(all_candidates) == 3:\n",
    "                break\n",
    "            all_candidates += [wtf]\n",
    "    candidates.append(all_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "minn = 10\n",
    "for i in candidates:\n",
    "    minn = min(len(i), minn)\n",
    "print(minn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_2(model_1: CosineRecommender, model_2: TFIDFRecommender, product_user_matrix: coo_matrix, user_ids_to_predict: ndarray, candidates: List[List[int]], user_id_to_compressed_user_id: pd.Series, course_id_to_compressed_course_id: pd.Series, compressed_course_id_to_course_id: pd.Series) -> List[ndarray]:\n",
    "    result_1 = list()\n",
    "    result_2 = list()\n",
    "    user_product_matrix = product_user_matrix.T.tocsr()\n",
    "    print(user_product_matrix.shape)\n",
    "\n",
    "    for user_id, transformed_user_id, cand in tqdm(zip(user_ids_to_predict, user_id_to_compressed_user_id[user_ids_to_predict].values, candidates)):\n",
    "        selected_items = course_id_to_compressed_course_id[cand].values\n",
    "        \n",
    "        rank_score_1 = model_1.rank_items(userid=transformed_user_id, user_items=user_product_matrix, selected_items=selected_items, recalculate_user=False)\n",
    "        reco_1 = [reco for (reco, score) in rank_score_1]\n",
    "        reco_1 = compressed_course_id_to_course_id[reco_1].values\n",
    "        rank_1 = np.arange(len(reco_1))\n",
    "        score_1 = [score for (reco, score) in rank_score_1]\n",
    "        \n",
    "        rank_score_2 = model_2.rank_items(userid=transformed_user_id, user_items=user_product_matrix, selected_items=selected_items, recalculate_user=False)\n",
    "        reco_2 = [reco for (reco, score) in rank_score_2]\n",
    "        reco_2 = compressed_course_id_to_course_id[reco_2].values\n",
    "        rank_2 = np.arange(len(reco_2))\n",
    "        score_2 = [score for (reco, score) in rank_score_2]\n",
    "        \n",
    "        result_1.append(pd.DataFrame({\"user_id\": user_id, \"course_id\": reco_1, \"rank_1\": rank_1, \"score_1\": score_1}))\n",
    "        result_2.append(pd.DataFrame({\"user_id\": user_id, \"course_id\": reco_2, \"rank_2\": rank_2, \"score_2\": score_2}))\n",
    "    return result_1, result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:00, 139.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5830, 173)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3017it [00:18, 160.26it/s]\n"
     ]
    }
   ],
   "source": [
    "result_1, result_2 = get_recommendations_2(model_1, model_2, course_user_matrix, user_ids_to_predict, candidates, user_id_to_compressed_user_id, course_id_to_compressed_course_id, compressed_course_id_to_course_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = pd.concat(result_1, ignore_index=True)\n",
    "result_2 = pd.concat(result_2, ignore_index=True)\n",
    "result = result_1.merge(result_2, \"left\", [\"user_id\", \"course_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.intersect1d(result_1[\"user_id\"].unique(), user_ids_to_predict).shape[0] == 3017\n",
    "assert np.intersect1d(result_2[\"user_id\"].unique(), user_ids_to_predict).shape[0] == 3017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18456524140978894"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"mean_rank\"] = result[[\"rank_1\", \"rank_2\"]].mean(axis=1)\n",
    "result = result.sort_values([\"user_id\", \"mean_rank\"]).groupby(\"user_id\", as_index=False).head(3)\n",
    "result = result.groupby(\"user_id\", as_index=False).agg({\"course_id\": lambda x: list(x.values)})\n",
    "\n",
    "res = list()\n",
    "for row in result.itertuples():\n",
    "    res.append(row.course_id)\n",
    "    \n",
    "mapk(actual, res, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = user_course_train[['user_id','course_id']].copy().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e41ac2ff7642e5b3be9e6806db96b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=173.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d404c04ea647a4b4b586125713286a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=173.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "173it [00:00, 1713.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "803it [00:00, 2396.20it/s]\n",
      "803it [00:00, 2749.55it/s]\n"
     ]
    }
   ],
   "source": [
    "n_users = X[\"user_id\"].nunique()\n",
    "n_courses = X[\"course_id\"].nunique()\n",
    "\n",
    "compressed_user_id_to_user_id, user_id_to_compressed_user_id = get_id_transformations(X, \"user_id\")\n",
    "compressed_course_id_to_course_id, course_id_to_compressed_course_id = get_id_transformations(X, \"course_id\")\n",
    "\n",
    "transform_with_transformation_inplace(\"user_id\", X, user_id_to_compressed_user_id)\n",
    "transform_with_transformation_inplace(\"course_id\", X, course_id_to_compressed_course_id)\n",
    "\n",
    "course_user_matrix_shape = (len(compressed_course_id_to_course_id), len(compressed_user_id_to_user_id))\n",
    "course_user_matrix = get_course_user_matrix(X[\"course_id\"], X[\"user_id\"], course_user_matrix_shape)\n",
    "\n",
    "model_1 = TFIDFRecommender(K=150)\n",
    "model_1.fit(course_user_matrix)\n",
    "\n",
    "model_2 = CosineRecommender(K=150)\n",
    "model_2.fit(course_user_matrix)\n",
    "\n",
    "predicted_1_1 = get_recommendations(model_1, course_user_matrix, group_1, user_id_to_compressed_user_id, compressed_course_id_to_course_id, N_RECO)\n",
    "predicted_1_2 = get_recommendations(model_2, course_user_matrix, group_1, user_id_to_compressed_user_id, compressed_course_id_to_course_id, N_RECO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = list()\n",
    "\n",
    "for i, j in zip(predicted_1_1, predicted_1_2):\n",
    "    all_candidates = list(set(i) | set(j))\n",
    "    if len(all_candidates) < 3:\n",
    "        for wtf in [7, 1, 15]:\n",
    "            if wtf in all_candidates:\n",
    "                continue\n",
    "            if len(all_candidates) == 3:\n",
    "                break\n",
    "            all_candidates += [wtf]\n",
    "    candidates.append(all_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "minn = 10\n",
    "for i in candidates:\n",
    "    minn = min(len(i), minn)\n",
    "print(minn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5830, 173)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "803it [00:04, 175.74it/s]\n"
     ]
    }
   ],
   "source": [
    "result_1, result_2 = get_recommendations_2(model_1, model_2, course_user_matrix, group_1, candidates, user_id_to_compressed_user_id, course_id_to_compressed_course_id, compressed_course_id_to_course_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = pd.concat(result_1, ignore_index=True)\n",
    "result_2 = pd.concat(result_2, ignore_index=True)\n",
    "result = result_1.merge(result_2, \"left\", [\"user_id\", \"course_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.intersect1d(result_1[\"user_id\"].unique(), group_1).shape[0] == 803\n",
    "assert np.intersect1d(result_2[\"user_id\"].unique(), group_1).shape[0] == 803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"mean_rank\"] = result[[\"rank_1\", \"rank_2\"]].mean(axis=1)\n",
    "result = result.sort_values([\"user_id\", \"mean_rank\"]).groupby(\"user_id\", as_index=False).head(3)\n",
    "predicted_1 = result.groupby(\"user_id\", as_index=False).agg({\"course_id\": lambda x: list(x.values)})\n",
    "predicted_1.rename(columns={\"course_id\": \"Predicted\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавляем к ркомендациям оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1_with_assessment = assessment_train.loc[assessment_train[\"user_id\"].isin(group_1)][\"user_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_a = assessment_train.loc[assessment_train[\"user_id\"].isin(group_1_with_assessment)].copy()\n",
    "dat_a[\"course_id\"] = dat_a[\"course_id\"].astype(int)\n",
    "dat_a = dat_a.groupby(\"user_id\")[\"course_id\"].apply(lambda x: set(x.values))\n",
    "dat_c = user_course_train.loc[user_course_train[\"user_id\"].isin(group_1_with_assessment)].groupby(\"user_id\")[\"course_id\"].apply(lambda x: set(x.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat_a - dat_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_1_1 = predicted_1.loc[predicted_1[\"user_id\"].isin(group_1_with_assessment)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_recommendations2(reco1: Set[int], reco2: List[int]) -> List[int]:\n",
    "    reco = list(reco1)[:3]\n",
    "    \n",
    "    for i in reco2:\n",
    "        if len(reco) == 3:\n",
    "            break\n",
    "        if i in reco:\n",
    "            continue\n",
    "        reco += [i]\n",
    "    return reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco = list()\n",
    "\n",
    "for i, j in zip(dat, predicted_1_1[\"Predicted\"]):\n",
    "    reco.append(add_missing_recommendations2(i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_1_2 = predicted_1.loc[predicted_1[\"user_id\"].isin(group_1[~np.isin(group_1, group_1_with_assessment)])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_1_1 = pd.DataFrame({\"user_id\": predicted_1_1[\"user_id\"].values, \"Predicted\": reco})\n",
    "predicted_1 = pd.concat((predicted_1_1, predicted_1_2), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекомендации для пользователей, по которым есть информация только про оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = assessment_train.loc[assessment_train[\"user_id\"].isin(group_2), [\"user_id\", \"course_id\"]].copy()\n",
    "X_2.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = user_course_train[['user_id','course_id']].copy().drop_duplicates()\n",
    "X = pd.concat((X, X_2), ignore_index=True)\n",
    "X[\"course_id\"] = X[\"course_id\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c87a178e5ad4addbca17287e30614c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "356it [00:00, 2254.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_users = X[\"user_id\"].nunique()\n",
    "n_courses = X[\"course_id\"].nunique()\n",
    "\n",
    "compressed_user_id_to_user_id, user_id_to_compressed_user_id = get_id_transformations(X, \"user_id\")\n",
    "compressed_course_id_to_course_id, course_id_to_compressed_course_id = get_id_transformations(X, \"course_id\")\n",
    "\n",
    "transform_with_transformation_inplace(\"user_id\", X, user_id_to_compressed_user_id)\n",
    "transform_with_transformation_inplace(\"course_id\", X, course_id_to_compressed_course_id)\n",
    "\n",
    "course_user_matrix_shape = (len(compressed_course_id_to_course_id), len(compressed_user_id_to_user_id))\n",
    "course_user_matrix = get_course_user_matrix(X[\"course_id\"], X[\"user_id\"], course_user_matrix_shape)\n",
    "\n",
    "model_1 = TFIDFRecommender(K=150)\n",
    "model_1.fit(course_user_matrix)\n",
    "\n",
    "# model_2 = CosineRecommender(K=150)\n",
    "# model_2.fit(course_user_matrix)\n",
    "\n",
    "predicted_2_1 = get_recommendations(model_1, course_user_matrix, group_2, user_id_to_compressed_user_id, compressed_course_id_to_course_id, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2[\"order\"] = 1\n",
    "X_2[\"order\"] = X_2.groupby(\"user_id\")[\"order\"].cumsum()\n",
    "X_2 = X_2.loc[X_2[\"order\"] <= 3].copy()\n",
    "X_2[\"course_id\"] = X_2[\"course_id\"].astype(int)\n",
    "X_2 = X_2.groupby(\"user_id\")[\"course_id\"].apply(lambda x: list(x.values)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_ = list()\n",
    "for row in X_2.itertuples():\n",
    "    assessment_.append(row.course_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_2 = list()\n",
    "for i, j in zip(assessment_, predicted_2_1):\n",
    "    predicted_2.append(add_missing_recommendations(i, j))\n",
    "\n",
    "X_2.rename(columns={\"course_id\": \"Predicted\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекомендации для пользователей, по которым нет информации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.concat((predicted_1, X_2), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = user_course_train[[\"user_id\", \"course_id\", \"created\"]].drop_duplicates(subset=\"user_id\").copy()\n",
    "X[\"created\"] = X[\"created\"].str.replace(\".\", \"-\")\n",
    "X[\"created\"] = X[\"created\"].apply(convert_to_datetime)\n",
    "X[\"date\"] = X[\"created\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X.copy()\n",
    "a[\"cnt\"] = 1\n",
    "a = a.pivot_table(values=\"cnt\", index=\"date\", columns=\"course_id\", aggfunc=\"sum\", fill_value=0, dropna=False)\n",
    "a = a.reset_index()\n",
    "a[\"date\"] = pd.to_datetime(a[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame({\"date\": pd.date_range('2018-10-10', periods=888, freq='D')})\n",
    "b = b.merge(a, \"left\", \"date\")\n",
    "b = b.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b.rolling(5, min_periods=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[\"date\"] = pd.DataFrame({\"date\": pd.date_range('2018-10-10', periods=888, freq='D')})\n",
    "b = b.set_index(\"date\")\n",
    "b = b.rank(axis=1, method=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_popularity = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in b.T.columns:\n",
    "    top_3 = b.T.nlargest(3, col).index.values.tolist()\n",
    "    course_popularity.append(top_3) # \" \".join([str(i) for i in top_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_popularity = pd.DataFrame({\"date\": b.T.columns.values, \"Predicted\": course_popularity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.groupby(\"date\").agg({\"user_id\": \"max\"})\n",
    "X[\"cum\"] = X[\"user_id\"].cummax()\n",
    "X.drop(columns=\"user_id\", inplace=True)\n",
    "X = X.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.DataFrame({\"date\": np.nan, \"cum\": group_3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.concat((X, c), ignore_index=True)\n",
    "c.sort_values(\"cum\", inplace=True)\n",
    "c[\"date\"] = c[\"date\"].fillna(method='backfill')\n",
    "c[\"date\"] = pd.to_datetime(c[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c.merge(course_popularity, \"left\", \"date\")\n",
    "c.rename(columns={\"cum\": \"user_id\"}, inplace=True)\n",
    "c = c.loc[c[\"user_id\"].isin(group_3)].copy()\n",
    "c.drop(columns=\"date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.concat((prediction, c), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(prediction, \"left\", \"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = get_submission(test) \n",
    "submission.to_csv(\"submission_25.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
